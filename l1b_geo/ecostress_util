#!/usr/bin/env python
# Various short utility programs, collected together so I don't need to search for these
import click
import logging
import glob
import subprocess
import ecostress
import pandas as pd
import pandasql as pds
import numpy as np
import matplotlib.pyplot as plt
import re
import os
import h5py

logger = logging.getLogger('ecostress_util')

# Setup logging
class ColorLogFormatter(logging.Formatter):
    '''Set logging format, optionally with color'''
    def __init__(self, add_color = True):
        self.add_color = add_color

    def color_text(self, text, levelno):
        # ANSI colors
        HEADER = '\033[95m'
        OKBLUE = '\033[94m'
        OKGREEN = '\033[92m'
        WARNING = '\033[93m'
        FAIL = '\033[91m'
        ENDC = '\033[0m'
        BOLD = '\033[1m'
        UNDERLINE = '\033[4m'
        if(not self.add_color):
            return text
        if(levelno == logging.DEBUG):
            return OKBLUE + text + ENDC
        elif(levelno == logging.INFO):
            return OKGREEN + text + ENDC
        elif(levelno == logging.WARNING):
            return WARNING + text + ENDC
        elif(levelno == logging.ERROR):
            return FAIL + text + ENDC
        elif(levelno == logging.CRITICAL):
            return FAIL + text + ENDC
        return text
    def format(self, record):
        return (self.color_text(record.levelname + " " +
                                self.formatTime(record) +
                                ": ", record.levelno) + record.getMessage())

loglevel = logging.INFO
h = logging.StreamHandler()
h.setLevel(loglevel)
h.setFormatter(ColorLogFormatter(add_color=True))
logger.addHandler(h)
logger.setLevel(loglevel)

def orb_scene_to_fname(flist, typ="L1B_GEO"):
    '''Make a dict from (orb,scene) to fname, accounting for multiple versions (taking the
    larger one.'''
    res = dict()
    ver = dict()
    for fname in flist:
        if(fname == ""):
            continue
        m = re.match(r'ECOv002_' + typ + '_(\d\d\d\d\d)_(\d\d\d)_.*_(\d\d\d\d)_(\d\d).h5',
                     os.path.basename(fname))
        if(not m):
            print(f"Don't recognize {fname}, skipping")
            continue
        orb = int(m.group(1))
        scene = int(m.group(2))
        build = m.group(3)
        version = m.group(4)
        if((orb,scene) in ver):
            cur_build, cur_version = ver[(orb,scene)]
            if(build > cur_build or
               (build == cur_build and version > cur_version)):
                res[(orb,scene)] = fname
                ver[(orb,scene)] = (build, version)
        else:
            res[(orb,scene)] = fname
            ver[(orb,scene)] = (build, version)
                
    return res

def orb_to_fname(flist):
    '''Make a dict from orb to fname, accounting for multiple versions (taking the
    larger one.'''
    res = dict()
    ver = dict()
    for fname in flist:
        if(fname == ""):
            continue
        m = re.match(r'L1B_GEO_QA_(\d\d\d\d\d)_.*_(\d\d\d\d)_(\d\d).h5',
                     os.path.basename(fname))
        if(not m):
            print(f"Don't recognize {fname}, skipping")
            continue
        orb = int(m.group(1))
        build = m.group(2)
        version = m.group(3)
        if(orb in ver):
            cur_build, cur_version = ver[orb]
            if(build > cur_build or
               (build == cur_build and version > cur_version)):
                res[orb] = fname
                ver[orb] = (build, version)
        else:
            res[orb] = fname
            ver[orb] = (build, version)
                
    return res

@click.group()
def cli():
    '''This is various utility routines for emit.
    '''
    pass

@cli.command()
@click.argument("flist", type=str)
def l1b_geo_file_list(flist):
    '''Find all the GEO files on the system. We have this as a separate step
    because it takes a while to run, and it is nice to just summarizes this once
    in while.

    Right now we only look for version 7, although we could change that'''
    subprocess.run(f"find /ops/store*/PRODUCTS/L1B_GEO/*/*/* -name 'ECOv002_L1B_GEO_*_07??_??.h5' | tee {flist}", shell=True)

@cli.command()
@click.argument("flist", type=str)
def l1b_geo_qa_file_list(flist):
    '''Find all the GEO QA files on the system. We have this as a separate step
    because it takes a while to run, and it is nice to just summarizes this once
    in while.

    Right now we only look for version 7, although we could change that'''
    subprocess.run(f"find /ops/store*/PRODUCTS/L1B_GEO_QA/*/*/* -name 'L1B_GEO_QA_*_07??_??.h5' | tee {flist}", shell=True)

@cli.command()
@click.argument("flist", type=str)
def l2_cloud_file_list(flist):
    '''Find all the L2 cloud files on the system. We have this as a separate step
    because it takes a while to run, and it is nice to just summarizes this once
    in while.

    Right now we only look for version 7, although we could change that'''
    subprocess.run(f"find /ops/store*/PRODUCTS/L2_CLOUD/*/*/* -name 'ECOv002_L2_CLOUD_*_071?_??.h5' | tee {flist}", shell=True)
    
@cli.command()
@click.argument("flist_fname", type=str)
@click.argument("panda_pickle", type=str)
def qvalue(flist_fname, panda_pickle):
    '''Take a list of orbits like l1b_geo_file_list generates, and generate a pandas
    file with the GeolocationAccuracyQA for each orbit/scene.'''
    flist = open(flist_fname).read().split("\n")
    oscene_to_fname = orb_scene_to_fname(flist)
    d = []
    for (orb, scene), fname in oscene_to_fname.items():
        try:
            logger.info(f"Processing {fname}")
            f = h5py.File(fname)
            v = f["/L1GEOMetadata/GeolocationAccuracyQA"][()]
            d.append([orb, scene, v.decode('utf-8')])
        except:
            logger.info(f"Error occurred, skipping {fname}")
    df = pd.DataFrame(d, columns=["Orbit", "Scene", "QA"])
    df.to_pickle(panda_pickle)

@cli.command()
@click.argument("flist_fname", type=str)
@click.argument("panda_pickle", type=str)
def cloud_fraction_pickle(flist_fname, panda_pickle):
    '''Take a list of orbits like l2_cloud_file_list generates, and generate a pandas
    file with the QAPercentCloudCover for each orbit/scene.'''
    flist = open(flist_fname).read().split("\n")
    oscene_to_fname = orb_scene_to_fname(flist, typ="L2_CLOUD")
    d = []
    nfile = len(oscene_to_fname)
    i = 0
    for (orb, scene), fname in oscene_to_fname.items():
        try:
            logger.info(f"Processing {fname} ({i}/{nfile})")
            i += 1
            f = h5py.File(fname)
            v = f["/L2 CLOUD Metadata/QAPercentCloudCover"][0]
            d.append([orb, scene, v])
        except:
            logger.info(f"Error occurred, skipping {fname}")
    df = pd.DataFrame(d, columns=["orbnum", "scene", "cloud_percentage"])
    df.to_pickle(panda_pickle)
    
@cli.command()
@click.argument("flist_fname", type=str)
@click.argument("panda_pickle", type=str)
def qa_summary_pickle(flist_fname, panda_pickle):
    '''Take a list of orbits like l1b_geo_qa_file_list generates, and generate a pandas
    file with the QA data for each orbit/scene.'''
    flist = open(flist_fname).read().split("\n")
    orbfname = orb_to_fname(flist)
    d = []
    for orb, fname in orbfname.items():
        logger.info(f"Processing {fname}")
        f = h5py.File(fname)
        # We save all this in a double array just for convenience,
        # even though some of the data is actually integer. The
        # columns in order are orbit, scene number, delta time before scene,
        # delta time after scene, accuracy
        # before correction, final accuracy, solar zenith, land
        # fraction, initial number tiepoint, blunders removed,
        # final number tiepoint, number image matching tries
        t = f["/Accuracy Estimate/Accuracy Before Correction"][:]
        d2 = np.empty((len(t), 12))
        d2[:,0] = int(orb)
        d2[:,1] = [int(f["Accuracy Estimate/Scenes"][i][6:])
                  for i in range(d2.shape[0])]
        d2[:,2] = t
        d2[:,3] = f["/Accuracy Estimate/Delta time correction after scene"][:]
        d2[:,4] = f["/Accuracy Estimate/Delta time correction before scene"][:]
        d2[:,5] = f["/Accuracy Estimate/Final Accuracy"][:]
        d2[:,6:8] = f["/Average Metadata"]
        d2[:,8:] = f["/Tiepoint/Tiepoint Count"]
        d.append(d2)
    d = np.concatenate(d, axis=0)
    df = pd.DataFrame(d, columns = ["orbnum",
                                    "scene",
                                    "initial_accuracy",
                                    "delta_time_after",
                                    "delta_time_before",
                                    "final_accuracy",
                                    "solar_zenith",
                                    "land_fraction",
                                    "initial_tiepoint",
                                    "blunder_removed",
                                    "final_tiepoint",
                                    "number_match_try"])
    df.to_pickle(panda_pickle)
    
@cli.command()
@click.argument("panda_pickle", type=str)
def summarize_qvalue(panda_pickle):
    '''Take a pickle file (like generated by qvalue) and generate a summary'''
    df = pd.read_pickle(panda_pickle)
    # If needed, before we changed qvalue to do this.
    df['QA'] = [i.decode('utf-8') for i in df['QA']]
    t = pds.PandaSQL(persist=True)
    total = np.array(t("select count(Orbit) from df"))[0,0]
    #total = np.count_nonzero(df['QA'])
    print(f"Total: {total}")
    for qa in ("Best", "Good", "Suspect", "Poor"):
        ttl = np.array(t(f"select count(Orbit) from df where QA='{qa}'"))[0,0]
        #ttl = np.count_nonzero(df['QA'] == qa)
        print(f"{qa}:  {ttl}  {(ttl / total)*100.0}%")

@cli.command()
@click.argument("panda_pickle", type=str)
def geoqa_summary(panda_pickle):
    '''Take a pickle file (like generated by qa_summary_pickle) and generate a summary'''
    df = pd.read_pickle(panda_pickle)
    print(f"68% geolocation {np.percentile(df[df.initial_accuracy>0]['final_accuracy'],68)}")
    
if __name__ == '__main__':
    cli()
